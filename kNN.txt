k-Nearest Neighbor is a supervised machine learning algorithm that can be used for classification or regression problems. The ML models that we are developing give a discrete output (ASL sign class) rather than a continuous output and thus, we will be using the kNN for classification. The kNN model operates under the assumption of proximity i.e. it assumes that things that belong to the same class will lie together. The similarity or closeness is usually measured by the euclidean distance between the points on a multi-dimensional graph. The k in kNN stands for the number of neighbors to be considered for classifying the data point. In classification, we use the mode of the labels of the k nearest points. The accuracy of the kNN model will change depending on the value of k. If we set the value of k to be too high or too low, the accuracy wil decrease. To find the right value of k, we need to run the algotithm multiple times and then choose the value of k that minimizes the error. The advantages of using this model is that it is fairly easy to implement and eliminates the need to build a complex model and tune multiple parameters.